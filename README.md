# ğŸ“˜ Moodle RAG Assistant

An **AI-powered Retrieval-Augmented Generation (RAG) assistant** integrated with **Moodle LMS** that can query both **unstructured data (PDF documents)** and **structured data (databases like students, teachers, grades, and attendance)**.  
Built with **Flask, LangChain, Ollama, and FAISS**, paired with a **modern TailwindCSS frontend**.

---

## âœ¨ Features
- ğŸ“‚ **Upload PDFs** â†’ Automatically processed and embedded into a **persistent FAISS vector store**  
- ğŸ§  **Unstructured Querying** â†’ Ask natural language questions on uploaded PDFs  
- ğŸ“Š **Structured Querying** â†’ Interact with SQLite databases (students, teachers, grades, attendance)  
- âš¡ **Dual Mode** â†’ Choose between *structured (SQL agent)* or *unstructured (RAG)* queries  
- ğŸ¨ **Modern UI** â†’ TailwindCSS-powered frontend with:
  - Light/Dark theme toggle  
  - Smooth animations  
  - Chat-style responses  
  - Query history  
  - Copy-to-clipboard feature  
- ğŸ”’ **Local-first** â†’ Runs with [Ollama](https://ollama.ai) for privacy and offline use  

---

## ğŸ—‚ï¸ Project Structure
moodle-rag-assistant/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py # Flask API entrypoint
â”‚ â”œâ”€â”€ config.py # Config: database mappings, table schemas
â”‚ â”œâ”€â”€ create_databases.py # Script to generate SQLite databases
â”‚ â”œâ”€â”€ document_loader.py # PDF loader and text extraction
â”‚ â”œâ”€â”€ rag_engine.py # RAG pipeline (Ollama + FAISS retriever)
â”‚ â”œâ”€â”€ sql_agent.py # SQL Agent for structured queries
â”‚ â”œâ”€â”€ vector_store.py # Persistent FAISS index handling
â”‚ â””â”€â”€ requirements.txt # Python dependencies
â””â”€â”€ frontend/
â””â”€â”€ index.html # TailwindCSS + JS frontend

yaml
Copy
Edit

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/SHREYAS-RODEO/moodle-rag-assistant.git
cd moodle-rag-assistant
2. Backend Setup
bash
Copy
Edit
cd backend
python -m venv venv
# On Linux/macOS:
source venv/bin/activate
# On Windows:
venv\Scripts\activate

pip install -r requirements.txt
3. Start Ollama
Install Ollama and pull a model (e.g., mistral):

bash
Copy
Edit
ollama pull mistral
ğŸ‘‰ If Ollama runs on Windows host but backend is inside WSL:

bash
Copy
Edit
# Get your Windows host IP
cat /etc/resolv.conf | grep nameserver

# Export it
export OLLAMA_BASE_URL=http://<windows-ip>:11434
4. Create Example Databases
bash
Copy
Edit
python create_databases.py
5. Run the Backend
bash
Copy
Edit
python app.py
Backend runs at: http://127.0.0.1:5000

ğŸŒ Frontend
Open the frontend directly in your browser:

bash
Copy
Edit
frontend/index.html
Features:
Upload PDFs

Choose query type (Structured DB / Unstructured PDF)

Chat-style assistant responses

Dark/Light theme toggle

Copy answers & view query history

âš¡ Example Usage
ğŸ”¹ Upload & Query PDFs
Upload research_paper.pdf

Ask:

Summarize the key contributions of this paper.

ğŸ”¹ Query Databases
Choose Structured Query â†’ Grades

Ask:

Show all students with grades above 80.

Response will be generated via the SQL agent.

ğŸ“Š Tech Stack
Backend: Python, Flask, LangChain, FAISS, SQLite

LLM: Ollama (mistral by default, configurable)

Frontend: HTML, TailwindCSS, Vanilla JavaScript

Databases: SQLite (students, teachers, grades, attendance)

ğŸ”® Future Roadmap
ğŸ“ˆ Charts & tables rendering for structured responses

ğŸ¤– Support multiple Ollama models (llama3, gemma, etc.)

ğŸ“‚ Multi-document management (upload + delete PDFs)

â˜ï¸ Deployment on cloud VM with Ollama remote endpoint

ğŸ‘¨â€ğŸ’» Author
Shreyas S Acharya
ğŸ“ Final-year Information Science Student @ NMIT
ğŸŒ Cloud & AI Enthusiast
â˜ï¸ Certified in AWS & GCP
ğŸ¤– Projects in LLMs, RAG, Flutter, and Cloud DevOps

pgsql
Copy
Edit

âš¡ This version is structured like a **real open-source project README** â€” clean sections, emojis for readability, setup instructions, usage examples, and roadmap.  

Do you want me to also make a **short "At a Glance" one-liner** (like a tagline) you can put right under the project title for recruiters scanning quickly?





You said:
i have to copy evrything and put it in the file so give me so that i can copy


ChatGPT said:
Here you go â€” everything is ready for you to copy-paste directly into your README.md file:

markdown
Copy
Edit
# ğŸ“˜ Moodle RAG Assistant

An **AI-powered Retrieval-Augmented Generation (RAG) assistant** integrated with **Moodle LMS** that can query both **unstructured data (PDF documents)** and **structured data (databases like students, teachers, grades, and attendance)**.  
Built with **Flask, LangChain, Ollama, and FAISS**, paired with a **modern TailwindCSS frontend**.

---

## âœ¨ Features
- ğŸ“‚ **Upload PDFs** â†’ Automatically processed and embedded into a **persistent FAISS vector store**  
- ğŸ§  **Unstructured Querying** â†’ Ask natural language questions on uploaded PDFs  
- ğŸ“Š **Structured Querying** â†’ Interact with SQLite databases (students, teachers, grades, attendance)  
- âš¡ **Dual Mode** â†’ Choose between *structured (SQL agent)* or *unstructured (RAG)* queries  
- ğŸ¨ **Modern UI** â†’ TailwindCSS-powered frontend with:
  - Light/Dark theme toggle  
  - Smooth animations  
  - Chat-style responses  
  - Query history  
  - Copy-to-clipboard feature  
- ğŸ”’ **Local-first** â†’ Runs with [Ollama](https://ollama.ai) for privacy and offline use  

---

## ğŸ—‚ï¸ Project Structure
moodle-rag-assistant/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py # Flask API entrypoint
â”‚ â”œâ”€â”€ config.py # Config: database mappings, table schemas
â”‚ â”œâ”€â”€ create_databases.py # Script to generate SQLite databases
â”‚ â”œâ”€â”€ document_loader.py # PDF loader and text extraction
â”‚ â”œâ”€â”€ rag_engine.py # RAG pipeline (Ollama + FAISS retriever)
â”‚ â”œâ”€â”€ sql_agent.py # SQL Agent for structured queries
â”‚ â”œâ”€â”€ vector_store.py # Persistent FAISS index handling
â”‚ â””â”€â”€ requirements.txt # Python dependencies
â””â”€â”€ frontend/
â””â”€â”€ index.html # TailwindCSS + JS frontend

yaml
Copy
Edit

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/SHREYAS-RODEO/moodle-rag-assistant.git
cd moodle-rag-assistant
2. Backend Setup
bash
Copy
Edit
cd backend
python -m venv venv
# On Linux/macOS:
source venv/bin/activate
# On Windows:
venv\Scripts\activate

pip install -r requirements.txt
3. Start Ollama
Install Ollama and pull a model (e.g., mistral):

bash
Copy
Edit
ollama pull mistral
ğŸ‘‰ If Ollama runs on Windows host but backend is inside WSL:

bash
Copy
Edit
# Get your Windows host IP
cat /etc/resolv.conf | grep nameserver

# Export it
export OLLAMA_BASE_URL=http://<windows-ip>:11434
4. Create Example Databases
bash
Copy
Edit
python create_databases.py
5. Run the Backend
bash
Copy
Edit
python app.py
Backend runs at: http://127.0.0.1:5000

ğŸŒ Frontend
Open the frontend directly in your browser:

bash
Copy
Edit
frontend/index.html
Features:
Upload PDFs

Choose query type (Structured DB / Unstructured PDF)

Chat-style assistant responses

Dark/Light theme toggle

Copy answers & view query history

âš¡ Example Usage
ğŸ”¹ Upload & Query PDFs
Upload research_paper.pdf

Ask:

Summarize the key contributions of this paper.

ğŸ”¹ Query Databases
Choose Structured Query â†’ Grades

Ask:

Show all students with grades above 80.

Response will be generated via the SQL agent.

ğŸ“Š Tech Stack
Backend: Python, Flask, LangChain, FAISS, SQLite

LLM: Ollama (mistral by default, configurable)

Frontend: HTML, TailwindCSS, Vanilla JavaScript

Databases: SQLite (students, teachers, grades, attendance)

ğŸ”® Future Roadmap
ğŸ“ˆ Charts & tables rendering for structured responses

ğŸ¤– Support multiple Ollama models (llama3, gemma, etc.)

ğŸ“‚ Multi-document management (upload + delete PDFs)

â˜ï¸ Deployment on cloud VM with Ollama remote endpoint

ğŸ‘¨â€ğŸ’» Author
Shreyas S Acharya
ğŸ“ Final-year Information Science Student @ NMIT
ğŸŒ Cloud & AI Enthusiast
â˜ï¸ Certified in AWS & GCP
ğŸ¤– Projects in LLMs, RAG, Flutter, and Cloud DevOps
